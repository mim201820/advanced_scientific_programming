{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python II - Assignment 2\n",
    "\n",
    "This **Home Assignment** is to be submitted and you will be given points for each of the tasks. It familiarizes you with basics of *web scraping* and basics of *regular expressions*.\n",
    "\n",
    "## Formalities\n",
    "**Submit in a group of 2-3 people until 22.06.2020 23:59CET. The deadline is strict!**\n",
    "\n",
    "## Evaluation and Grading\n",
    "General advice for programming excercises at *CSSH*:\n",
    "Evaluation of your submission is done semi automatically. Think of it as this notebook being \n",
    "executed once. Afterwards, some test functions are appended to this file and executed respectively.\n",
    "\n",
    "Therefore:\n",
    "* Submit valid _Python3_ code only!\n",
    "* Use external libraries only when specified by task.\n",
    "* Ensure your definitions (functions, classes, methods, variables) follow the specification if\n",
    "  given. The concrete signature of e.g. a function usually can be inferred from task description, \n",
    "  code skeletons and test cases.\n",
    "* Ensure the notebook does not rely on current notebook or system state!\n",
    "  * Use `Kernel --> Restart & Run All` to see if you are using any definitions, variables etc. that \n",
    "    are not in scope anymore.\n",
    "  * Double check if your code relies on presence of files or directories other than those mentioned\n",
    "    in given tasks. Tests run under Linux, hence don't use Windows style paths \n",
    "    (`some\\path`, `C:\\another\\path`). Also, use paths only that are relative to and within your\n",
    "    working directory (OK: `some/path`, `./some/path`; NOT OK: `/home/alice/python`, \n",
    "    `../../python`).\n",
    "* Keep your code idempotent! Running it or parts of it multiple times must not yield different\n",
    "  results. Minimize usage of global variables.\n",
    "* Ensure your code / notebook terminates in reasonable time.\n",
    "\n",
    "**There's a story behind each of these points! Don't expect us to fix your stuff!**\n",
    "\n",
    "Regarding the scores, you will get no points for a task if:\n",
    "- your function throws an unexpected error (e.g. takes the wrong number of arguments)\n",
    "- gets stuck in an infinite loop\n",
    "- takes much much longer than expected (e.g. >1s to compute the mean of two numbers)\n",
    "- does not produce the desired output (e.g. returns an descendingly sorted list even though we asked for ascending, returns the mean and the std even though we asked for the mean only, only prints the output instead of returning it!)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History in Wikipedia (10 points total)\n",
    "\n",
    "Wikipedia has a lot of information on historic events. Assume you want to conduct a study that examines which language edition talks more about different historic event (as indicated by years). As an example you first consider the article \"History_of_Germany\" in the englisch and german wikipedia.\n",
    "\n",
    "To get articles from the web, use the `requests` library. To deal with html content you can use the Beautiful soup library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Grabbing a wikipedia article (1 + 0.5 + 0.5 + 0.5)\n",
    "Write a function `get_article_from_web(article_name, language_edition)` that returns the HTML as string for that article in a specific language edition. Assume that the article exists.\n",
    "\n",
    "To save bandwith when conducting multiple experiments we want to setup a cache of wikipedia articles.\n",
    "To setup the cache write the function `save_article_to_disk(article_name, language_edition, content)` that saves the content for that wikipedia article in `'./cache/{language_edition}/{article_name}.html'`. If any of the folders do not exist they are created. Please read the information on evaluation and grading.\n",
    "\n",
    "\n",
    "Then write a function `get_article_from_disk(article_name, language_edition)` that returns the cached version of the article from disk. If the article does not exists, it raises a `ValueError`.\n",
    "\n",
    "\n",
    "Write a function `get_article(article_name, language_edition)` that uses a local cache for fetching articles from wikipedia. So if you that article exists in cache it returns the cached version. If not it fetches the html for that article from the web and writes it to the cache so there is no need to get it from the web the next time. Thereby use the previously defined functions.\n",
    "\n",
    "Use the \"caching\" version `get_article` for all of the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_from_web(article_name, language_edition):\n",
    "    # define the dictionary for the language edition\n",
    "#     language_prefix = {'Deutsch':'de','deutsch':'de','de':'de',\n",
    "#                        'English':'en','english':'en','en':'en'}\n",
    "    \n",
    "    global API_URL\n",
    "#     API_URL = 'https://' + language_prefix[language_edition] + '.wikipedia.org/wiki/' + article_name  \n",
    "    API_URL = 'https://' + language_edition + '.wikipedia.org/wiki/' + article_name\n",
    "\n",
    "    #S = requests\n",
    "    page = requests.get(url=API_URL,timeout=30)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    return soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_article_to_disk(article_name, language_edition, content):\n",
    "    try:\n",
    "        os.makedirs(f\"./cache/{language_edition}\")\n",
    "    except :\n",
    "        pass\n",
    "    \n",
    "    my_file=open(f\"./cache/{language_edition}/{article_name}.html\",\"w\", encoding=\"utf-8\")\n",
    "    my_file.write(content)\n",
    "    my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_from_disk(article_name, language_edition):\n",
    "    try:\n",
    "        with open(f\"./cache/{language_edition}/{article_name}.html\",\"r\",encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    except FileNotFoundError: \n",
    "        raise ValueError(\"The article does not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(article_name, language_edition):\n",
    "    try:\n",
    "        return get_article_from_disk(article_name,language_edition)\n",
    "    except:\n",
    "        content=get_article_from_web(article_name,language_edition)\n",
    "        save_article_to_disk(article_name,language_edition,content)\n",
    "        return get_article_from_disk(article_name,language_edition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_article(\"Germany\",\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Links from one article to other articles  (1)\n",
    "Write a function `get_links(article_name, language_edition)` that returns a list of wikipedia article names.  These links are obtained throught the article specified by `article_name` (in the language_edition). Only include links in its 'content' div. Do not include links that you can get through the left navigation bar.\n",
    "\n",
    "Sort the links in alphabetically increasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(article_name, language_edition):\n",
    "    page_content = get_article(article_name, language_edition)\n",
    "    # convert the string file to soup\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    links = []\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        l=str(link.get('href'))\n",
    "        if l.startswith(\"/w\") and ('Wikipedia' not in l) and ('index' not in l) and (\"File\" not in l):\n",
    "            b=f\"https://{language_edition}.wikipedia.org\"+l\n",
    "            if b not in links:\n",
    "                links.append(b)\n",
    "    return sorted(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_links(\"Germany\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all(class_=\"interlanguage-link-target\",)[9]['href']\n",
    "# soup.find_all(class_=\"interlanguage-link-target\",)[0]\n",
    "# soup.find_all(class_=\"interlanguage-link-target\",)[0]['lang']\n",
    "# len_lang = len(soup.find_all(class_=\"interlanguage-link-target\",))\n",
    "# len_lang = 10\n",
    "# for i in range(len_lang):\n",
    "#     names = soup.find_all(class_=\"interlanguage-link-target\",)[i]['title']\n",
    "#     print(soup.find_all(class_=\"interlanguage-link-target\",)[i].get_text(),\n",
    "#           soup.find_all(class_=\"interlanguage-link-target\",)[i]['lang'],\n",
    "#           names.split(' ')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Getting the same article in a different language edition (1.0)\n",
    "Write a funciton `switch_language(article_name, old_language_edition, new_language_edition)` that returns the name of the wikipedia article in the new language edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_language(article_name, old_language_edition, new_language_edition):\n",
    "    page_content = get_article(article_name, old_language_edition)\n",
    "    # convert the string file to soup\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    wiki_new_lang = soup.find_all(class_=\"interlanguage-link-target\",lang=new_language_edition)\n",
    "    new_name_article = \" \".join(wiki_new_lang[0]['title'].split()[:-2]) \n",
    "    return new_name_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Geschichte Deutschlands'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_language(\"History_of_Germany\",\"en\", \"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_content = get_article(\"Germany\",\"en\")\n",
    "#     # convert the string file to soup\n",
    "# soup = BeautifulSoup(page_content, 'html.parser')\n",
    "# wiki_new_lang = soup.find_all(class_=\"interlanguage-link-target\",lang=\"de\")\n",
    "# wiki_new_lang[0].get_text().split()[0]\n",
    "# wiki_new_lang = soup.find_all(class_=\"interlanguage-link-target\",lang=\"de\")\n",
    "# wiki_new_lang[0]['title'].split()[0]\n",
    "\n",
    "# soup.find_all(class_=\"interlanguage-link-target\",)[9]['href']\n",
    "# soup.find_all(class_=\"interlanguage-link-target\",)[0]\n",
    "# soup.find_all(class_=\"interlanguage-link-target\",lang=\"de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Using regular expressions to extract years from a page content (1.5)\n",
    "Write a function `extract_years(string_input)` that gets a string and returns how often a certain year number from 1000-2019 occurs. You can assume that each number between 1000 and 2020 is a year number. The result is a dictionary with year numbers as keys, and the number of occurrences as values.\n",
    "\n",
    "Example: `extract_years(\"The king reigned from 1245 to 1268. He died in 1268. His favorite number was 12689\")` should return the dictionary `{1245: 1, 1268:2}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_years(string_input):\n",
    "    L=re.findall(\"\\\\b(1\\d{3}|20[0-1]\\d|2020)\\\\b\",string_input)\n",
    "    D={}\n",
    "    for a in L:\n",
    "        if a not in D:\n",
    "            D[a]=L.count(a)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1245': 1, '1268': 2, '2020': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_years(\"The king reigned from 1245 to 1268. He died in 1268. His favorite number was 12689 and 2021 and 19999 and 2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Aggregate years for articles (0.5)\n",
    "Write a function `extract_years_for_articles(article_names, language_edition)` that extracts the years counts for all the articles in that particular language edition and aggregates them into a single dictionary. This aggregated dictionary is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_years_for_articles(article_names, language_edition):\n",
    "    \n",
    "    dict_years = dict()\n",
    "    for article_name in  article_names:\n",
    "        \n",
    "        page_content = get_article(article_name,language_edition)\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "        text_extracted = soup.get_text()\n",
    "        years_of_one_article = extract_years(text_extracted)\n",
    "        \n",
    "        # concatenate the dictionary of years\n",
    "        for key,val in years_of_one_article.items():\n",
    "                try:\n",
    "                    # if the year (key) exist in the dictionary then adds the new value to its value\n",
    "                    dict_years[key] = dict_years[key] + val\n",
    "                except KeyError:\n",
    "                    # if the year (key) does not exist in the dictionary then adds the new key and its corresponding value to it\n",
    "                    dict_years[key] = val\n",
    "        \n",
    "    return dict_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1949': 34,\n",
       " '1990': 43,\n",
       " '1871': 38,\n",
       " '1918': 53,\n",
       " '1933': 43,\n",
       " '2019': 113,\n",
       " '2018': 34,\n",
       " '1815': 35,\n",
       " '1919': 21,\n",
       " '1024': 2,\n",
       " '1125': 3,\n",
       " '1138': 1,\n",
       " '1254': 2,\n",
       " '1315': 2,\n",
       " '1348': 1,\n",
       " '1356': 4,\n",
       " '1483': 2,\n",
       " '1546': 2,\n",
       " '1517': 4,\n",
       " '1555': 4,\n",
       " '1618': 8,\n",
       " '1648': 26,\n",
       " '1495': 1,\n",
       " '1438': 2,\n",
       " '1740': 5,\n",
       " '1772': 4,\n",
       " '1793': 3,\n",
       " '1795': 4,\n",
       " '1806': 9,\n",
       " '1848': 19,\n",
       " '1862': 4,\n",
       " '1866': 23,\n",
       " '1882': 3,\n",
       " '1884': 2,\n",
       " '1914': 43,\n",
       " '1924': 3,\n",
       " '1945': 67,\n",
       " '1929': 7,\n",
       " '1932': 9,\n",
       " '1935': 12,\n",
       " '1936': 14,\n",
       " '1938': 10,\n",
       " '1939': 16,\n",
       " '1942': 7,\n",
       " '1940': 8,\n",
       " '1941': 7,\n",
       " '1943': 2,\n",
       " '1944': 9,\n",
       " '1947': 12,\n",
       " '1948': 10,\n",
       " '1955': 8,\n",
       " '1961': 7,\n",
       " '1989': 20,\n",
       " '1994': 12,\n",
       " '1999': 15,\n",
       " '1992': 14,\n",
       " '2007': 26,\n",
       " '2005': 38,\n",
       " '2009': 30,\n",
       " '2015': 59,\n",
       " '2020': 133,\n",
       " '2016': 51,\n",
       " '1844': 4,\n",
       " '2017': 60,\n",
       " '2011': 77,\n",
       " '2001': 12,\n",
       " '2014': 53,\n",
       " '2002': 18,\n",
       " '1386': 1,\n",
       " '1810': 4,\n",
       " '1286': 1,\n",
       " '2013': 42,\n",
       " '1770': 12,\n",
       " '1827': 3,\n",
       " '1818': 3,\n",
       " '1838': 1,\n",
       " '1854': 3,\n",
       " '1895': 2,\n",
       " '1912': 5,\n",
       " '1927': 2,\n",
       " '1979': 8,\n",
       " '1951': 1,\n",
       " '2012': 26,\n",
       " '1954': 2,\n",
       " '1974': 9,\n",
       " '1972': 4,\n",
       " '1980': 6,\n",
       " '1996': 24,\n",
       " '1952': 8,\n",
       " '1991': 28,\n",
       " '1998': 29,\n",
       " '2010': 30,\n",
       " '1073': 2,\n",
       " '1038': 4,\n",
       " '1982': 9,\n",
       " '1400': 4,\n",
       " '1381': 2,\n",
       " '2004': 29,\n",
       " '1916': 4,\n",
       " '2000': 19,\n",
       " '1317': 1,\n",
       " '1346': 2,\n",
       " '1351': 3,\n",
       " '1017': 10,\n",
       " '1997': 6,\n",
       " '1959': 5,\n",
       " '1789': 9,\n",
       " '1934': 7,\n",
       " '1111': 5,\n",
       " '1468': 2,\n",
       " '1173': 1,\n",
       " '1214': 1,\n",
       " '1093': 4,\n",
       " '1898': 5,\n",
       " '1177': 5,\n",
       " '2008': 32,\n",
       " '1922': 2,\n",
       " '1976': 5,\n",
       " '2003': 35,\n",
       " '1080': 3,\n",
       " '1962': 5,\n",
       " '1986': 9,\n",
       " '2006': 27,\n",
       " '1086': 6,\n",
       " '1987': 7,\n",
       " '1500': 5,\n",
       " '1800': 18,\n",
       " '1957': 6,\n",
       " '1921': 3,\n",
       " '1950': 8,\n",
       " '1956': 4,\n",
       " '1803': 2,\n",
       " '1900': 12,\n",
       " '1917': 8,\n",
       " '1888': 8,\n",
       " '1890': 15,\n",
       " '1907': 3,\n",
       " '1856': 2,\n",
       " '1858': 4,\n",
       " '1864': 4,\n",
       " '1300': 7,\n",
       " '1200': 4,\n",
       " '1988': 10,\n",
       " '1027': 1,\n",
       " '1180': 3,\n",
       " '1531': 2,\n",
       " '1700': 2,\n",
       " '1240': 2,\n",
       " '1452': 1,\n",
       " '1039': 1,\n",
       " '1056': 5,\n",
       " '1077': 1,\n",
       " '1122': 1,\n",
       " '1095': 1,\n",
       " '1291': 1,\n",
       " '1157': 1,\n",
       " '1361': 1,\n",
       " '1370': 1,\n",
       " '1450': 2,\n",
       " '1135': 1,\n",
       " '1230': 3,\n",
       " '1525': 2,\n",
       " '1155': 1,\n",
       " '1190': 2,\n",
       " '1340': 1,\n",
       " '1347': 2,\n",
       " '1137': 1,\n",
       " '1156': 2,\n",
       " '1176': 1,\n",
       " '1183': 1,\n",
       " '1184': 1,\n",
       " '1186': 1,\n",
       " '1212': 1,\n",
       " '1250': 2,\n",
       " '1338': 1,\n",
       " '1378': 1,\n",
       " '1526': 2,\n",
       " '1742': 1,\n",
       " '1745': 1,\n",
       " '1493': 5,\n",
       " '1519': 1,\n",
       " '1288': 1,\n",
       " '1411': 1,\n",
       " '1572': 1,\n",
       " '1478': 1,\n",
       " '1504': 1,\n",
       " '1098': 2,\n",
       " '1179': 2,\n",
       " '1170': 2,\n",
       " '1439': 1,\n",
       " '1486': 1,\n",
       " '1512': 2,\n",
       " '1398': 1,\n",
       " '1193': 1,\n",
       " '1280': 1,\n",
       " '1494': 1,\n",
       " '1471': 1,\n",
       " '1528': 1,\n",
       " '1460': 1,\n",
       " '1521': 1,\n",
       " '1529': 1,\n",
       " '1530': 3,\n",
       " '1524': 1,\n",
       " '1545': 1,\n",
       " '1547': 1,\n",
       " '1608': 1,\n",
       " '1609': 1,\n",
       " '1625': 1,\n",
       " '1630': 5,\n",
       " '1635': 2,\n",
       " '1650': 2,\n",
       " '1534': 1,\n",
       " '1472': 1,\n",
       " '1553': 1,\n",
       " '1571': 1,\n",
       " '1646': 1,\n",
       " '1716': 3,\n",
       " '1651': 1,\n",
       " '1708': 1,\n",
       " '1680': 1,\n",
       " '1621': 1,\n",
       " '1676': 1,\n",
       " '1593': 1,\n",
       " '1763': 4,\n",
       " '1640': 1,\n",
       " '1713': 1,\n",
       " '1750': 9,\n",
       " '1678': 2,\n",
       " '1681': 1,\n",
       " '1688': 1,\n",
       " '1697': 3,\n",
       " '1689': 2,\n",
       " '1683': 2,\n",
       " '1687': 1,\n",
       " '1686': 1,\n",
       " '1699': 1,\n",
       " '1786': 5,\n",
       " '1748': 1,\n",
       " '1738': 2,\n",
       " '1811': 2,\n",
       " '1760': 5,\n",
       " '1785': 4,\n",
       " '1820': 2,\n",
       " '1737': 1,\n",
       " '1783': 1,\n",
       " '1807': 3,\n",
       " '1809': 2,\n",
       " '1849': 1,\n",
       " '1830': 1,\n",
       " '1780': 3,\n",
       " '1757': 1,\n",
       " '1831': 3,\n",
       " '1850': 12,\n",
       " '1870': 14,\n",
       " '1805': 5,\n",
       " '1860': 3,\n",
       " '1679': 1,\n",
       " '1754': 1,\n",
       " '1685': 3,\n",
       " '1598': 1,\n",
       " '1744': 1,\n",
       " '1749': 3,\n",
       " '1832': 4,\n",
       " '1759': 3,\n",
       " '1732': 1,\n",
       " '1756': 2,\n",
       " '1791': 1,\n",
       " '1724': 2,\n",
       " '1804': 2,\n",
       " '1813': 5,\n",
       " '1792': 3,\n",
       " '1797': 4,\n",
       " '1812': 1,\n",
       " '1814': 2,\n",
       " '1834': 3,\n",
       " '1865': 2,\n",
       " '1840': 12,\n",
       " '1873': 4,\n",
       " '1833': 1,\n",
       " '1841': 1,\n",
       " '1880': 2,\n",
       " '1729': 2,\n",
       " '1781': 2,\n",
       " '1828': 1,\n",
       " '1826': 3,\n",
       " '1883': 5,\n",
       " '1863': 3,\n",
       " '1859': 5,\n",
       " '1775': 1,\n",
       " '1788': 1,\n",
       " '1920': 8,\n",
       " '1768': 1,\n",
       " '1886': 2,\n",
       " '1769': 2,\n",
       " '1777': 2,\n",
       " '1855': 2,\n",
       " '1787': 2,\n",
       " '1816': 1,\n",
       " '1892': 1,\n",
       " '1845': 3,\n",
       " '1837': 1,\n",
       " '1819': 2,\n",
       " '1857': 2,\n",
       " '1861': 1,\n",
       " '1867': 2,\n",
       " '1868': 2,\n",
       " '1878': 7,\n",
       " '1894': 4,\n",
       " '1875': 3,\n",
       " '1872': 2,\n",
       " '1879': 5,\n",
       " '1913': 8,\n",
       " '1877': 2,\n",
       " '1887': 2,\n",
       " '1885': 2,\n",
       " '1915': 2,\n",
       " '1897': 3,\n",
       " '1910': 2,\n",
       " '1905': 2,\n",
       " '1911': 1,\n",
       " '1881': 2,\n",
       " '1926': 4,\n",
       " '1906': 1,\n",
       " '1923': 6,\n",
       " '1925': 3,\n",
       " '1928': 4,\n",
       " '1931': 4,\n",
       " '1930': 2,\n",
       " '1821': 2,\n",
       " '1902': 1,\n",
       " '1843': 1,\n",
       " '1968': 4,\n",
       " '1889': 2,\n",
       " '1901': 2,\n",
       " '1937': 1,\n",
       " '1946': 4,\n",
       " '1893': 1,\n",
       " '1973': 5,\n",
       " '1971': 6,\n",
       " '1969': 6,\n",
       " '1953': 2,\n",
       " '1958': 5,\n",
       " '1876': 1,\n",
       " '1967': 5,\n",
       " '1977': 11,\n",
       " '1963': 4,\n",
       " '1966': 7,\n",
       " '1904': 2,\n",
       " '1960': 2,\n",
       " '1970': 2,\n",
       " '1964': 6,\n",
       " '1975': 4,\n",
       " '1983': 1,\n",
       " '1371': 1,\n",
       " '1829': 1,\n",
       " '1163': 1,\n",
       " '1482': 2,\n",
       " '1995': 14,\n",
       " '1159': 1,\n",
       " '1984': 6,\n",
       " '1487': 1,\n",
       " '1229': 2,\n",
       " '1154': 1,\n",
       " '1050': 3,\n",
       " '1194': 1,\n",
       " '1903': 1,\n",
       " '1273': 2,\n",
       " '1000': 2,\n",
       " '1057': 1,\n",
       " '1965': 3,\n",
       " '1710': 1,\n",
       " '1600': 6,\n",
       " '1790': 2,\n",
       " '1715': 2,\n",
       " '1993': 9,\n",
       " '1985': 8,\n",
       " '1817': 1,\n",
       " '1004': 1,\n",
       " '1978': 5,\n",
       " '1869': 1,\n",
       " '1981': 2,\n",
       " '1853': 1,\n",
       " '1007': 1,\n",
       " '1055': 1,\n",
       " '1094': 1,\n",
       " '1467': 1,\n",
       " '1162': 1,\n",
       " '1215': 1,\n",
       " '1560': 1,\n",
       " '1168': 1,\n",
       " '1270': 1,\n",
       " '1908': 1,\n",
       " '1477': 1,\n",
       " '1120': 1,\n",
       " '1380': 1,\n",
       " '1382': 1,\n",
       " '1266': 1,\n",
       " '1353': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_years_for_articles([\"Germany\", \"history_of_Germany\"],\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Bringing it all together (1.5)\n",
    "Write a function `get_all_years(base_article, base_language_edition, n=None, target_language_edition=None)`\n",
    "\n",
    "- Determines 'real' base article (if target_language edition is specified, the article in the target language edition is used.)\n",
    "- extracts the first n links (all if n is None) from that 'real' base article\n",
    "- aggregates the year counts across the base article **and** all the n articles that the base article links to.\n",
    "- it then returns that dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) Visualize and Interpret your results (1 + 1)\n",
    "Visualize the numbers of occurrences for the article History_of_Germany in both englisch (en) and german (de) in a timeline. Use `n=20`. Show the results here in the notebook and also save it to 'timeline.png' in code. Make sure the plot has a legend, axis labels, ...\n",
    "\n",
    "Describe the visualization, and give reasons for possible differences of the german and englisch timelines. Write that string to a file 'timeline.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "279px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
